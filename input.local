# -*-sh-*-
# ------------------------------------------------------------------------------------------------
# ------------------------------------------------------------------------------------------------
# Template input file to define local variable settings for use with
# an OpenHPC installation recipe.
# ------------------------------------------------------------------------------------------------

# ---------------------------
# SMS (master) node settings
# ---------------------------

# Hostname for master server (SMS)
sms_name="${sms_name:-sms}"

# Local (internal) IP address on SMS
sms_ip="${sms_ip:-192.168.72.1}"

# DNS domain name and ip
dns_domain="${dns_domain:-sms}"
dns_servers="${dns_servers:-192.168.72.1}"


# Internal ethernet interface on SMS
sms_eth_internal="${sms_eth_internal:-ens2f0}"

# Subnet netmask for internal cluster network
internal_netmask="${internal_netmask:-255.255.252.0}"

# Local ntp server for time synchronization
ntp_server="${ntp_server:-0.centos.pool.ntp.org}"

# BMC user credentials for use by IPMI
bmc_username="${bmc_username:-USERID}"
bmc_password="${bmc_password:-P@ssw0rd12}"

# Additional time to wait for compute nodes to provision (seconds)
provision_wait="${provision_wait:-180}"

# Local domainname for cluster (xCAT and confluent recipe only)
domain_name="${domain_name:-local}"

# Path to copy of OS ISO image (xCAT and confluent recipe only)
iso_path="${iso_path:-/root/os/}"
initialize_options="${initialize_options:-usklpt}"

# Path to local repository web roots (Confluent recipe only)
ohpc_repo_dir="${ohpc_repo_dir:-/var/lib/confluent/public/ohpc}"
ohpc_repo_remote_dir="${ohpc_repo_remote_dir:-/confluent-public/ohpc}"
epel_repo_dir="${epel_repo_dir:-/var/lib/confluent/public/epel}"
epel_repo_remote_dir="${epel_repo_remote_dir:-/confluent-public/epel}"

# Provisioning interface used by compute hosts (Warewulf recipe only)
eth_provision="${eth_provision:-eth0}"

# Flags for optional installation/configuration
enable_ib="${enable_ib:-0}"
enable_opa="${enable_opa:-0}"
enable_opafm="${enable_opafm:-0}"
enable_mpi_defaults="${enable_mpi_defaults:-1}"
enable_mpich_ucx="${enable_mpich_ucx:-1}"
enable_ipoib="${enable_ipoib:-0}"

enable_clustershell="${enable_clustershell:-0}"
enable_ipmisol="${enable_ipmisol:-0}"
enable_opensm="${enable_opensm:-0}"
enable_genders="${enable_genders:-0}"
enable_magpie="${enable_magpie:-0}"
enable_kargs="${enable_kargs:-0}"
enable_beegfs_client="${enable_beegfs_client:-0}"
enable_lustre_client="${enable_lustre_client:-0}"
enable_mrsh="${enable_mrsh:-0}"
enable_powerman="${enable_powerman:-0}"
enable_pmix="${enable_pmix:-0}"
enable_geopm="${enable_geopm:-0}"

# Vendor compiler package flags
enable_intel_packages="${enable_intel_packages:-0}"
enable_arm1_packages="${enable_arm1_packages:-0}"

update_slurm_nodeconfig="${update_slurm_nodeconfig:-0}"

#-----------------------------
# compute node group settings
# ----------------------------

deployment_protocols="${deployment_protocols:-firmware}"
console_method="${console_method:-ipmi}"


# -------------------------
# compute node settings
# -------------------------

# total number of computes
num_computes="${num_computes:-4}"

# regex and starting prefix that matches defined compute hostnames
compute_regex="${compute_regex:-c*}"
compute_prefix="${compute_prefix:-c}"

# compute hostnames
c_name[0]=${c_name[0]:-c1}
c_name[1]=${c_name[1]:-c2}
c_name[2]=${c_name[2]:-c3}
c_name[3]=${c_name[3]:-c4}

# compute node IP addresses
c_ip[0]=${c_ip[0]:-192.168.72.2}
c_ip[1]=${c_ip[1]:-192.168.72.3}
c_ip[2]=${c_ip[2]:-192.168.72.4}
c_ip[3]=${c_ip[3]:-192.168.72.5}

# compute node MAC addreses for provisioning interface
c_mac[0]=${c_mac[0]:-00:1a:2b:3c:4f:56}
c_mac[1]=${c_mac[1]:-00:1a:2b:3c:4f:57}
c_mac[2]=${c_mac[2]:-00:1a:2b:3c:4f:58}
c_mac[3]=${c_mac[3]:-00:1a:2b:3c:4f:59}

# compute node BMC addresses
c_bmc[0]=${c_bmc[0]:-192.168.72.10}
c_bmc[1]=${c_bmc[1]:-192.168.72.11}
c_bmc[2]=${c_bmc[2]:-192.168.72.13}
c_bmc[3]=${c_bmc[3]:-192.168.72.14}

# compute node BMC mac address
c_bmac[0]=${c_bmac[0]:-08:94:ef:55:45:6d}
c_bmac[1]=${c_bmac[1]:-08:94:ef:59:1b:df}
c_bmac[2]=${c_bmac[2]:-08:94:ef:59:1c:ab}
c_bmac[3]=${c_bmac[3]:-08:94:ef:78:ce:eb}

# Slurm node config
slurm_node_config="${slurm_node_config:-${compute_prefix}[1-${num_computes}] Sockets=2 CoresPerSocket=10 ThreadsPerCore=2}"

#-------------------
# Optional settings
#-------------------

# additional arguments to enable optional arguments for bootstrap kernel
kargs="${kargs:-acpi_pad.disable=1}"

# BeeGFS repository URL
beegfs_repo="${beegfs_repo:-https://www.beegfs.io/release/beegfs_6/dists/beegfs-rhel7.repo}"

# BeeGFS sysMgmtdHost
sysmgmtd_host="${sysmgmtd_host:-172.17.1.16}"

# Lustre MGS mount name
mgs_fs_name="${mgs_fs_name:-192.168.100.254@o2ib:/lustre1}"

# Subnet netmask for IPoIB network
ipoib_netmask="${ipoib_netmask:-255.255.0.0}"

# IPoIB address for SMS server
sms_ipoib="${sms_ipoib:-192.168.0.1}"

# IPoIB addresses for computes
c_ipoib[0]=${c_ipoib[0]:-192.168.1.1}
c_ipoib[1]=${c_ipoib[1]:-192.168.1.2}
c_ipoib[2]=${c_ipoib[2]:-192.168.1.3}
c_ipoib[3]=${c_ipoib[3]:-192.168.1.4}